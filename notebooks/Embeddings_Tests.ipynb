{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edges(G, train_G, c, epc):\n",
    "    st = time.time()\n",
    "    for i in range(c):\n",
    "        edges_in_clique = 0\n",
    "        while edges_in_clique <= epc:\n",
    "            a = random.randint(npc*i, npc*(i+1))\n",
    "            b = random.randint(npc*i, npc*(i+1))\n",
    "            if a != b:\n",
    "                G.add_edge(a, b)\n",
    "                train_G.add_edge(a, b)\n",
    "                edges_in_clique += 1\n",
    "    run_time = time.time() - st\n",
    "#     print(\"Add edges:\", round(run_time, 4))\n",
    "    return G, train_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleton_nodes(G, train_G, nodes):\n",
    "    # Create an edge for any singleton nodes\n",
    "    st = time.time()\n",
    "    limit = 0\n",
    "    for node in nodes:\n",
    "        while len(list(G.neighbors(node))) < connect_num:\n",
    "            b = random.randint(0, n-1)\n",
    "            limit += 1\n",
    "            if b != node:\n",
    "                G.add_edge(node, b)\n",
    "                train_G.add_edge(node, b)\n",
    "            if limit > m*20:\n",
    "                print('singleton nodes - had to break')\n",
    "                break\n",
    "    run_time = time.time() - st\n",
    "#     print(\"Singleton Nodes:\", round(run_time, 4))\n",
    "    return G, train_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_set(train_G, connect_num, test_size):\n",
    "    st = time.time()\n",
    "    test_edges = []\n",
    "    labels = []\n",
    "    limit = 0\n",
    "    while len(test_edges) < test_size:\n",
    "        h_u, h_v = random.choice(list(train_G.edges))\n",
    "        u_neighbors = len(list(train_G.neighbors(h_u)))\n",
    "        v_neighbors = len(list(train_G.neighbors(h_v)))\n",
    "        if u_neighbors > connect_num and v_neighbors > connect_num:\n",
    "            train_G.remove_edge(h_u, h_v)\n",
    "            test_edges.append((h_u, h_v))\n",
    "            labels.append(1)\n",
    "            limit -= 1\n",
    "        limit +=1 \n",
    "        if limit > m*100:\n",
    "            print('split_test_set - had to break', len(test_edges), test_size)\n",
    "            break\n",
    "    run_time = time.time() - st\n",
    "#     print(\"Split test set:\", round(run_time, 4))\n",
    "    return train_G, test_edges, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_negative_test(G, test_edges, test_size, labels):\n",
    "    st = time.time()\n",
    "    limit = 0\n",
    "    ts = len(test_edges)\n",
    "    while len(test_edges) < ts * 2:\n",
    "        a = random.randint(0, n-1)\n",
    "        b = random.randint(0, n-1)\n",
    "        if G.has_edge(a, b) == False and a != b:\n",
    "            test_edges.append((a , b))\n",
    "            labels.append(0)\n",
    "            limit -= 1\n",
    "        limit +=1\n",
    "        if limit > m*100:\n",
    "            print('negatives - had to break', len(test_edges), test_size)\n",
    "            break\n",
    "    run_time = time.time() - st\n",
    "#     print(\"Add negatives:\", round(run_time, 4))\n",
    "    return test_edges, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_walks(train_G, nodes, walks_per_node, walk_length):\n",
    "    st = time.time()\n",
    "    walks = []\n",
    "    for node in nodes:\n",
    "        for walk in range(walks_per_node):\n",
    "            nodes_in_walk = [str(node)]\n",
    "            cur_node = node\n",
    "            for step in range(walk_length - 1):\n",
    "                neigh = list(train_G.neighbors(cur_node))\n",
    "                next_step = random.choice(neigh)\n",
    "                cur_node = next_step\n",
    "                nodes_in_walk.append(str(next_step))\n",
    "            walks.append(nodes_in_walk)\n",
    "    run_time = time.time() - st\n",
    "#     print(\"Generate walks:\", round(run_time, 4))\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(walks, dim_order, test_edges, labels):\n",
    "    st = time.time()\n",
    "    model = Word2Vec(size=2**dim_order, window=window, workers=16, \n",
    "                                           ns_exponent =-0.5,\n",
    "                                           sg=1, hs=0, negative=5)\n",
    "    model.build_vocab(walks)\n",
    "    losses = []\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model.train(walks, total_examples=len(walks),\n",
    "                epochs=10, compute_loss=True)\n",
    "        losses.append(model.get_latest_training_loss())\n",
    "        preds = []\n",
    "        for t in test_edges:\n",
    "            pred = model.wv.similarity(str(t[0]), str(t[1]))\n",
    "            preds.append(pred)\n",
    "        auc = roc_auc_score(labels, preds)\n",
    "        aucs.append(auc)\n",
    "    run_time = time.time() - st\n",
    "#     print(\"Test model:\", round(run_time, 4))\n",
    "    return losses, aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for c in range(1, 10, 2): # 5\n",
    "    for connect_num in range(2, 7, 2): # 3\n",
    "        for npc in range(8, 24, 2): # 8\n",
    "            for epc in range(3, 104, 3): # 153\n",
    "                for window in range(1, 11, 3): # 4\n",
    "                    st = time.time()\n",
    "                    n = c * (npc ** 2)\n",
    "                    m = c * (epc ** 3)\n",
    "                    D = 2 * m / (n * (n-1))\n",
    "                    test_size = int(m * 0.2)\n",
    "                    G=nx.Graph()\n",
    "                    train_G=nx.Graph()\n",
    "\n",
    "                    nodes = [x for x in range(n)]\n",
    "                    G.add_nodes_from(nodes)\n",
    "                    train_G.add_nodes_from(nodes)\n",
    "\n",
    "                    G, train_G = add_edges(G, train_G, c, epc)\n",
    "\n",
    "                    G, train_G = singleton_nodes(G, train_G, nodes)\n",
    "                    \n",
    "#                     nx.draw_networkx(G)\n",
    "#                     plt.show()\n",
    "\n",
    "                    train_G, test_edges, labels = split_test_set(train_G, connect_num, test_size)\n",
    "\n",
    "                    test_edges, labels = add_negative_test(G, test_edges, test_size, labels)\n",
    "                    \n",
    "                    if m >= n and D < 1 and len(test_edges) > 10:\n",
    "                        walk_length = 80\n",
    "                        walks_per_node = 10\n",
    "                        \n",
    "                        walks = generate_walks(train_G, nodes, walks_per_node, walk_length)\n",
    "\n",
    "                        for dim_order in range(1, 9):\n",
    "                            losses, aucs = test_model(walks, dim_order, test_edges, labels)  \n",
    "                            results.append([c, D, npc, epc, connect_num, window, 2**dim_order, np.mean(losses[-5:]), min(losses), np.mean(aucs[-5:]), max(aucs)])\n",
    "                        \n",
    "                        if len(results) % 1 == 0:\n",
    "                            run_time = time.time() - st\n",
    "                            print(\"Time:\", round(run_time, 4))\n",
    "                            print(np.array(walks).shape) \n",
    "                            print(\"Nodes:\", n)\n",
    "                            print(\"Edges:\", m)\n",
    "                            print(\"Graph Density:\", D)\n",
    "                            print(\"Connectivity:\", connect_num)\n",
    "                            print(\"Cliques:\", c)\n",
    "                            print(\"Window:\", window)\n",
    "                            print(\"Test size:\", len(test_edges))    \n",
    "                            print(2**dim_order, np.mean(losses[-5:]), min(losses), np.mean(aucs[-5:]), max(aucs))\n",
    "                            columns = [\"cliques\", \"density\", \"nodes per clique\", \"edges per clique\", \n",
    "                                       \"connectivity between cliques\", \"w2v window\", \"w2v dimensions\", \n",
    "                                       \"average loss\", \"min loss\", \"[average auc]\", \"max auc\"]\n",
    "                            results_df = pd.DataFrame(results, columns = columns)\n",
    "                            results_df.to_csv('HyperParameter_Results_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(results_df['average auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
